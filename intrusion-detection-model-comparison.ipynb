{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5795572,"sourceType":"datasetVersion","datasetId":2228769}],"dockerImageVersionId":30474,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-26T11:05:16.107779Z","iopub.execute_input":"2023-12-26T11:05:16.108820Z","iopub.status.idle":"2023-12-26T11:05:17.424624Z","shell.execute_reply.started":"2023-12-26T11:05:16.108770Z","shell.execute_reply":"2023-12-26T11:05:17.423399Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/unridd-intrusion-detection-dataset/dataset.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/unridd-intrusion-detection-dataset/UNR-IDD.csv\")\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:31.059494Z","iopub.execute_input":"2023-05-11T15:03:31.059919Z","iopub.status.idle":"2023-05-11T15:03:31.09863Z","shell.execute_reply.started":"2023-05-11T15:03:31.059881Z","shell.execute_reply":"2023-05-11T15:03:31.097483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:31.101829Z","iopub.execute_input":"2023-05-11T15:03:31.102283Z","iopub.status.idle":"2023-05-11T15:03:31.124864Z","shell.execute_reply.started":"2023-05-11T15:03:31.102243Z","shell.execute_reply":"2023-05-11T15:03:31.123348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:31.126784Z","iopub.execute_input":"2023-05-11T15:03:31.127345Z","iopub.status.idle":"2023-05-11T15:03:31.263052Z","shell.execute_reply.started":"2023-05-11T15:03:31.127312Z","shell.execute_reply":"2023-05-11T15:03:31.261896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.apply(pd.Series.value_counts)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:31.264676Z","iopub.execute_input":"2023-05-11T15:03:31.265071Z","iopub.status.idle":"2023-05-11T15:03:34.907323Z","shell.execute_reply.started":"2023-05-11T15:03:31.26504Z","shell.execute_reply":"2023-05-11T15:03:34.906227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data=df, x=\"Binary Label\")","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:34.908506Z","iopub.execute_input":"2023-05-11T15:03:34.908809Z","iopub.status.idle":"2023-05-11T15:03:35.188742Z","shell.execute_reply.started":"2023-05-11T15:03:34.908784Z","shell.execute_reply":"2023-05-11T15:03:35.187421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=df[\"Label\"])","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:35.190726Z","iopub.execute_input":"2023-05-11T15:03:35.191199Z","iopub.status.idle":"2023-05-11T15:03:35.468984Z","shell.execute_reply.started":"2023-05-11T15:03:35.191135Z","shell.execute_reply":"2023-05-11T15:03:35.467918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Binary Label\"].unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:35.470267Z","iopub.execute_input":"2023-05-11T15:03:35.470596Z","iopub.status.idle":"2023-05-11T15:03:35.480707Z","shell.execute_reply.started":"2023-05-11T15:03:35.470568Z","shell.execute_reply":"2023-05-11T15:03:35.479689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Label\"].unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:35.485222Z","iopub.execute_input":"2023-05-11T15:03:35.485576Z","iopub.status.idle":"2023-05-11T15:03:35.498959Z","shell.execute_reply.started":"2023-05-11T15:03:35.485549Z","shell.execute_reply":"2023-05-11T15:03:35.497669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Port Number\"].unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:35.500566Z","iopub.execute_input":"2023-05-11T15:03:35.500872Z","iopub.status.idle":"2023-05-11T15:03:35.511908Z","shell.execute_reply.started":"2023-05-11T15:03:35.500847Z","shell.execute_reply":"2023-05-11T15:03:35.510757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Switch ID\"].unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:35.513623Z","iopub.execute_input":"2023-05-11T15:03:35.514119Z","iopub.status.idle":"2023-05-11T15:03:35.525049Z","shell.execute_reply.started":"2023-05-11T15:03:35.514088Z","shell.execute_reply":"2023-05-11T15:03:35.523963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:35.526432Z","iopub.execute_input":"2023-05-11T15:03:35.527427Z","iopub.status.idle":"2023-05-11T15:03:35.542342Z","shell.execute_reply.started":"2023-05-11T15:03:35.527353Z","shell.execute_reply":"2023-05-11T15:03:35.541161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:35.544023Z","iopub.execute_input":"2023-05-11T15:03:35.54438Z","iopub.status.idle":"2023-05-11T15:03:35.609001Z","shell.execute_reply.started":"2023-05-11T15:03:35.544351Z","shell.execute_reply":"2023-05-11T15:03:35.607682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.hist(bins = 50,figsize = (15,15))","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:35.610387Z","iopub.execute_input":"2023-05-11T15:03:35.613489Z","iopub.status.idle":"2023-05-11T15:03:42.741614Z","shell.execute_reply.started":"2023-05-11T15:03:35.613441Z","shell.execute_reply":"2023-05-11T15:03:42.740407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-processing","metadata":{}},{"cell_type":"code","source":"#['Attack', 'Normal']=[1,0]\ndf_a=df[df['Binary Label']=='Attack']\ndf_n=df[df['Binary Label']=='Normal']\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:42.743795Z","iopub.execute_input":"2023-05-11T15:03:42.74426Z","iopub.status.idle":"2023-05-11T15:03:42.772142Z","shell.execute_reply.started":"2023-05-11T15:03:42.74422Z","shell.execute_reply":"2023-05-11T15:03:42.771068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_a","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:42.773419Z","iopub.execute_input":"2023-05-11T15:03:42.773728Z","iopub.status.idle":"2023-05-11T15:03:42.813717Z","shell.execute_reply.started":"2023-05-11T15:03:42.773703Z","shell.execute_reply":"2023-05-11T15:03:42.812841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_n['Label'].nunique())\n# no need to use df_n as it has nomal\ndf_n.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:42.815066Z","iopub.execute_input":"2023-05-11T15:03:42.815387Z","iopub.status.idle":"2023-05-11T15:03:42.837753Z","shell.execute_reply.started":"2023-05-11T15:03:42.81536Z","shell.execute_reply":"2023-05-11T15:03:42.836551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_a=df_a.drop('Binary Label', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:42.839357Z","iopub.execute_input":"2023-05-11T15:03:42.84056Z","iopub.status.idle":"2023-05-11T15:03:42.850229Z","shell.execute_reply.started":"2023-05-11T15:03:42.840515Z","shell.execute_reply":"2023-05-11T15:03:42.848957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_a[\"Port Number\"]=df_a[\"Port Number\"].replace(['Port#:1', 'Port#:2', 'Port#:3', 'Port#:4'],[1,2,3,4])\ndf_a[\"Switch ID\"]=df_a[\"Switch ID\"].replace(['of:000000000000000c', 'of:000000000000000a',\n       'of:000000000000000b', 'of:0000000000000003',\n       'of:0000000000000004', 'of:0000000000000001',\n       'of:0000000000000002', 'of:0000000000000007',\n       'of:0000000000000008', 'of:0000000000000005',\n       'of:0000000000000006', 'of:0000000000000009'],[12,10,11,3,4,1,2,7,8,5,6,9])\n\ndf_a['Label']=df_a['Label'].replace(['TCP-SYN', 'Blackhole', 'Diversion', 'Overflow','PortScan'],\n                   [0,1,2,3,4])","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:42.851564Z","iopub.execute_input":"2023-05-11T15:03:42.85242Z","iopub.status.idle":"2023-05-11T15:03:43.00931Z","shell.execute_reply.started":"2023-05-11T15:03:42.852386Z","shell.execute_reply":"2023-05-11T15:03:43.008123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_a.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:43.010908Z","iopub.execute_input":"2023-05-11T15:03:43.011309Z","iopub.status.idle":"2023-05-11T15:03:43.030465Z","shell.execute_reply.started":"2023-05-11T15:03:43.011237Z","shell.execute_reply":"2023-05-11T15:03:43.029223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf['Label'].value_counts().plot(kind='pie',autopct='%1.2f%%')\nplt.title(\"Hacking Count\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:43.032008Z","iopub.execute_input":"2023-05-11T15:03:43.032348Z","iopub.status.idle":"2023-05-11T15:03:43.248798Z","shell.execute_reply.started":"2023-05-11T15:03:43.03232Z","shell.execute_reply":"2023-05-11T15:03:43.247054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(df_a.corr(), annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:43.25149Z","iopub.execute_input":"2023-05-11T15:03:43.25523Z","iopub.status.idle":"2023-05-11T15:03:45.319925Z","shell.execute_reply.started":"2023-05-11T15:03:43.255153Z","shell.execute_reply":"2023-05-11T15:03:45.318905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pairplot for particular features\n\n# plt_df = df_a[['Switch ID', 'Port Number', 'Received Packets', 'Received Bytes',\n#        'Sent Bytes', 'Sent Packets', 'Port alive Duration (S)',\n#        'Packets Rx Dropped', 'Packets Tx Dropped', 'Packets Rx Errors',\n#        'Packets Tx Errors', 'Delta Received Packets', 'Delta Received Bytes',\n#        'Delta Sent Bytes', 'Delta Sent Packets',\n#        'Delta Port alive Duration (S)', 'Delta Packets Rx Dropped',\n#        ' Delta Packets Tx Dropped', 'Delta Packets Rx Errors',\n#        'Delta Packets Tx Errors', 'Connection Point', 'Total Load/Rate',\n#        'Total Load/Latest', 'Unknown Load/Rate', 'Unknown Load/Latest',\n#        'Latest bytes counter', 'is_valid', 'Table ID', 'Active Flow Entries',\n#        'Packets Looked Up', 'Packets Matched', 'Max Size', 'Label']]\n# fig =sns.pairplot(data = plt_df,hue=\"Label\",corner=True);\n# fig.savefig(\"out.png\") ","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:45.32135Z","iopub.execute_input":"2023-05-11T15:03:45.321756Z","iopub.status.idle":"2023-05-11T15:03:45.327488Z","shell.execute_reply.started":"2023-05-11T15:03:45.321727Z","shell.execute_reply":"2023-05-11T15:03:45.326188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport joblib \nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:45.329252Z","iopub.execute_input":"2023-05-11T15:03:45.32958Z","iopub.status.idle":"2023-05-11T15:03:45.926436Z","shell.execute_reply.started":"2023-05-11T15:03:45.329553Z","shell.execute_reply":"2023-05-11T15:03:45.925279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_a.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:45.92779Z","iopub.execute_input":"2023-05-11T15:03:45.928919Z","iopub.status.idle":"2023-05-11T15:03:45.946073Z","shell.execute_reply.started":"2023-05-11T15:03:45.928882Z","shell.execute_reply":"2023-05-11T15:03:45.944713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into dependant and independant fetature\n\nX = df_a.drop(['Label','Packets Rx Dropped', 'Packets Tx Dropped', 'Packets Rx Errors',\n       'Packets Tx Errors','Delta Packets Rx Dropped',\n       ' Delta Packets Tx Dropped', 'Delta Packets Rx Errors',\n       'Delta Packets Tx Errors', 'is_valid', 'Table ID','Max Size'],axis =1)\ny = df_a[\"Label\"]","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:45.947706Z","iopub.execute_input":"2023-05-11T15:03:45.948149Z","iopub.status.idle":"2023-05-11T15:03:45.957039Z","shell.execute_reply.started":"2023-05-11T15:03:45.948111Z","shell.execute_reply":"2023-05-11T15:03:45.955723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:45.966666Z","iopub.execute_input":"2023-05-11T15:03:45.967042Z","iopub.status.idle":"2023-05-11T15:03:45.976226Z","shell.execute_reply.started":"2023-05-11T15:03:45.96701Z","shell.execute_reply":"2023-05-11T15:03:45.974785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape,y.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:45.97788Z","iopub.execute_input":"2023-05-11T15:03:45.978317Z","iopub.status.idle":"2023-05-11T15:03:45.989129Z","shell.execute_reply.started":"2023-05-11T15:03:45.978232Z","shell.execute_reply":"2023-05-11T15:03:45.987651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:45.990495Z","iopub.execute_input":"2023-05-11T15:03:45.990848Z","iopub.status.idle":"2023-05-11T15:03:46.017538Z","shell.execute_reply.started":"2023-05-11T15:03:45.990819Z","shell.execute_reply":"2023-05-11T15:03:46.016368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building & Training:\n   Supervised machine learning is one of the most commonly used and successful types of machine learning. Supervised learning is used whenever we want to predict a certain outcome/label from a given set of features, and we have examples of features-label pairs. We build a machine learning model from these features-label pairs, which comprise our training set. Our goal is to make accurate predictions for new, never-before-seen data.\n\n   There are two major types of supervised machine learning problems, called classification and regression. Our data set comes under regression problem, as the prediction of suicide rate is a continuous number, or a floating-point number in programming terms. The supervised machine learning models (regression) considered to train the dataset in this notebook are:\n\n1. Logistic Regression\n2. k-Nearest Neighbors \n3. Support Vector Clasifier\n4. Naive Bayes\n5. Decision Tree\n6. Random Forest\n7. Gradient Boosting\n8. Catboost\n9. Xgboost\n10. Multilayer Perceptrons\n\n              \n  The metrics considered to evaluate the model performance are Accuracy & F1 score.","metadata":{}},{"cell_type":"code","source":"# Creating holders to store the model performance results\nfrom sklearn import metrics \nML_Model = []\naccuracy = []\nf1_score = []\nrecall = []\nprecision = []\n\n#function to call for storing the results\ndef storeResults(model, a,b,c,d):\n    ML_Model.append(model)\n    accuracy.append(round(a, 3))\n    f1_score.append(round(b, 3))\n    recall.append(round(c, 3))\n    precision.append(round(d, 3))","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:46.019108Z","iopub.execute_input":"2023-05-11T15:03:46.019579Z","iopub.status.idle":"2023-05-11T15:03:46.02711Z","shell.execute_reply.started":"2023-05-11T15:03:46.019539Z","shell.execute_reply":"2023-05-11T15:03:46.026014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_report(modelname,y_train,y_test,p_train,p_test):\n    #computing the accuracy, f1_score, Recall, precision of the model performance\n    #computing the classification report of the model\n    #storing the results. The below mentioned order of parameter passing is important\n    print(\"Model:{}\\n\".format(modelname))\n    \n    acc_train = metrics.accuracy_score(y_train,p_train)\n    acc_test = metrics.accuracy_score(y_test,p_test)\n    print(\"Accuracy on training Data: {:.3f}\".format(acc_train))\n    print(\"Accuracy on test Data: {:.3f}\\n\".format(acc_test))\n    \n    f1_score_train = metrics.f1_score(y_train,p_train,average='micro')\n    f1_score_test = metrics.f1_score(y_test,p_test,average='micro')\n    print(\"f1_score on training Data: {:.3f}\".format(f1_score_train))\n    print(\"f1_score on test Data: {:.3f}\\n\".format(f1_score_test))\n    \n\n    recall_score_train = metrics.recall_score(y_train,p_train,average='micro')\n    recall_score_test = metrics.recall_score(y_test,p_test,average='micro')\n    print(\"Recall on training Data: {:.3f}\".format(recall_score_train))\n    print(\"Recall on test Data: {:.3f}\\n\".format(recall_score_test))\n\n    precision_score_train = metrics.precision_score(y_train,p_train,average='micro')\n    precision_score_test = metrics.precision_score(y_test,p_test,average='micro')\n    print(\"Precision on training Data: {:.3f}\".format(precision_score_train))\n    print(\"Precision on test Data: {:.3f}\\n\".format(precision_score_test))\n    #computing the classification report of the model\n    print(\"Classification Report\")\n    print(metrics.classification_report(y_test, p_test))\n    \n    #storing the results\n    storeResults(modelname,acc_test,f1_score_test,\n             recall_score_test,precision_score_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:46.028361Z","iopub.execute_input":"2023-05-11T15:03:46.028765Z","iopub.status.idle":"2023-05-11T15:03:46.044796Z","shell.execute_reply.started":"2023-05-11T15:03:46.028729Z","shell.execute_reply":"2023-05-11T15:03:46.043693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression\n\nLogistic regression predicts the output of a categorical dependent variable. Therefore the outcome must be a categorical or discrete value. Logistic Regression is much similar to the Linear Regression except that how they are used. Linear Regression is used for solving Regression problems, whereas Logistic regression is used for solving the classification problems.","metadata":{}},{"cell_type":"code","source":"# Linear regression model \nfrom sklearn.linear_model import LogisticRegression\n#from sklearn.pipeline import Pipeline\n\n# instantiate the model\nlog = LogisticRegression()\n\n# fit the model \nlog.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:46.046205Z","iopub.execute_input":"2023-05-11T15:03:46.046511Z","iopub.status.idle":"2023-05-11T15:03:47.506911Z","shell.execute_reply.started":"2023-05-11T15:03:46.046487Z","shell.execute_reply":"2023-05-11T15:03:47.505404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\n\np_train_log = log.predict(X_train)\np_test_log = log.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:47.509076Z","iopub.execute_input":"2023-05-11T15:03:47.510619Z","iopub.status.idle":"2023-05-11T15:03:47.536056Z","shell.execute_reply.started":"2023-05-11T15:03:47.510554Z","shell.execute_reply":"2023-05-11T15:03:47.534276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel_report(str(log),y_train,y_test,p_train_log,p_test_log)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:47.53897Z","iopub.execute_input":"2023-05-11T15:03:47.539607Z","iopub.status.idle":"2023-05-11T15:03:47.669135Z","shell.execute_reply.started":"2023-05-11T15:03:47.539554Z","shell.execute_reply":"2023-05-11T15:03:47.668014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K-Nearest Neighbors : Classifier\n\nK-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique. K-NN algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories.","metadata":{}},{"cell_type":"code","source":"# K-Nearest Neighbors Classifier model\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# instantiate the model\nknn = KNeighborsClassifier(n_neighbors=5)\n\n# fit the model \nknn.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:47.670496Z","iopub.execute_input":"2023-05-11T15:03:47.670812Z","iopub.status.idle":"2023-05-11T15:03:47.683511Z","shell.execute_reply.started":"2023-05-11T15:03:47.670778Z","shell.execute_reply":"2023-05-11T15:03:47.682324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_accuracy = []\ntest_accuracy = []\n# try max_depth from 1 to 20\ndepth = range(1,20)\nfor n in depth:\n    knn1 = KNeighborsClassifier(n_neighbors=n)\n\n    knn1.fit(X_train, y_train)\n    # record training set accuracy\n    training_accuracy.append(knn1.score(X_train, y_train))\n    # record generalization accuracy\n    test_accuracy.append(knn1.score(X_test, y_test))\n    \n\n#plotting the training & testing accuracy for n_estimators from 1 to 20\nplt.plot(depth, training_accuracy, label=\"training accuracy\")\nplt.plot(depth, test_accuracy, label=\"test accuracy\")\nplt.ylabel(\"Accuracy\")  \nplt.xlabel(\"n_neighbors\")\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:03:47.68503Z","iopub.execute_input":"2023-05-11T15:03:47.685431Z","iopub.status.idle":"2023-05-11T15:09:24.268182Z","shell.execute_reply.started":"2023-05-11T15:03:47.6854Z","shell.execute_reply":"2023-05-11T15:09:24.26697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\np_train_knn = knn.predict(X_train)\np_test_knn = knn.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:24.269551Z","iopub.execute_input":"2023-05-11T15:09:24.269892Z","iopub.status.idle":"2023-05-11T15:09:42.675783Z","shell.execute_reply.started":"2023-05-11T15:09:24.269862Z","shell.execute_reply":"2023-05-11T15:09:42.674374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_report(str(knn),y_train,y_test,p_train_knn,p_test_knn)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:42.677256Z","iopub.execute_input":"2023-05-11T15:09:42.677603Z","iopub.status.idle":"2023-05-11T15:09:42.754921Z","shell.execute_reply.started":"2023-05-11T15:09:42.677574Z","shell.execute_reply":"2023-05-11T15:09:42.753764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Naive Bayes : Classifier\n\nNaïve Bayes algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems.It is mainly used in text, image classification that includes a high-dimensional training dataset. Naïve Bayes Classifier is one of the simple and most effective Classification algorithms which helps in building the fast machine learning models that can make quick predictions.","metadata":{}},{"cell_type":"code","source":"# Naive Bayes Classifier Model\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.pipeline import Pipeline\n\n# instantiate the model\nnb=  GaussianNB()\n\n# fit the model \nnb.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:42.756514Z","iopub.execute_input":"2023-05-11T15:09:42.757333Z","iopub.status.idle":"2023-05-11T15:09:42.789034Z","shell.execute_reply.started":"2023-05-11T15:09:42.757299Z","shell.execute_reply":"2023-05-11T15:09:42.788221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\np_train_nb = nb.predict(X_train)\np_test_nb = nb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:42.790474Z","iopub.execute_input":"2023-05-11T15:09:42.790805Z","iopub.status.idle":"2023-05-11T15:09:42.817816Z","shell.execute_reply.started":"2023-05-11T15:09:42.790776Z","shell.execute_reply":"2023-05-11T15:09:42.816768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_report(str(nb),y_train,y_test,p_train_nb,p_test_nb)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:42.819304Z","iopub.execute_input":"2023-05-11T15:09:42.820077Z","iopub.status.idle":"2023-05-11T15:09:42.899067Z","shell.execute_reply.started":"2023-05-11T15:09:42.820037Z","shell.execute_reply":"2023-05-11T15:09:42.897869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Decision Trees : Classifier\n\nDecision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.","metadata":{}},{"cell_type":"code","source":"# Decision Tree Classifier model \nfrom sklearn.tree import DecisionTreeClassifier\n\n# instantiate the model \ntree = DecisionTreeClassifier(max_depth=30)\n\n# fit the model \ntree.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:42.900537Z","iopub.execute_input":"2023-05-11T15:09:42.903145Z","iopub.status.idle":"2023-05-11T15:09:43.272235Z","shell.execute_reply.started":"2023-05-11T15:09:42.903099Z","shell.execute_reply":"2023-05-11T15:09:43.271145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\n\np_train_tree = tree.predict(X_train)\np_test_tree = tree.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:43.273864Z","iopub.execute_input":"2023-05-11T15:09:43.274533Z","iopub.status.idle":"2023-05-11T15:09:43.289641Z","shell.execute_reply.started":"2023-05-11T15:09:43.274495Z","shell.execute_reply":"2023-05-11T15:09:43.288623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_report(str(tree),y_train,y_test,p_train_nb,p_test_tree)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:43.291195Z","iopub.execute_input":"2023-05-11T15:09:43.291831Z","iopub.status.idle":"2023-05-11T15:09:43.367345Z","shell.execute_reply.started":"2023-05-11T15:09:43.291798Z","shell.execute_reply":"2023-05-11T15:09:43.366086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_accuracy = []\ntest_accuracy = []\n# try max_depth from 1 to 30\ndepth = range(1,30)\nfor n in depth:\n    tree_test = DecisionTreeClassifier(max_depth=n)\n\n    tree_test.fit(X_train, y_train)\n    # record training set accuracy\n    training_accuracy.append(tree_test.score(X_train, y_train))\n    # record generalization accuracy\n    test_accuracy.append(tree_test.score(X_test, y_test))\n    \n\n#plotting the training & testing accuracy for max_depth from 1 to 30\nplt.plot(depth, training_accuracy, label=\"training accuracy\")\nplt.plot(depth, test_accuracy, label=\"test accuracy\")\nplt.ylabel(\"Accuracy\")  \nplt.xlabel(\"max_depth\")\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:43.368339Z","iopub.execute_input":"2023-05-11T15:09:43.368649Z","iopub.status.idle":"2023-05-11T15:09:52.081015Z","shell.execute_reply.started":"2023-05-11T15:09:43.368623Z","shell.execute_reply":"2023-05-11T15:09:52.080229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Random Forest : Classifier\n\nRandom Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model.","metadata":{}},{"cell_type":"code","source":"# Random Forest Classifier Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n# instantiate the model\nforest = RandomForestClassifier(n_estimators=10)\n\n# fit the model \nforest.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:52.082264Z","iopub.execute_input":"2023-05-11T15:09:52.082754Z","iopub.status.idle":"2023-05-11T15:09:52.731652Z","shell.execute_reply.started":"2023-05-11T15:09:52.082725Z","shell.execute_reply":"2023-05-11T15:09:52.730289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\np_train_forest = forest.predict(X_train)\np_test_forest = forest.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:52.733037Z","iopub.execute_input":"2023-05-11T15:09:52.733429Z","iopub.status.idle":"2023-05-11T15:09:52.813162Z","shell.execute_reply.started":"2023-05-11T15:09:52.733388Z","shell.execute_reply":"2023-05-11T15:09:52.812118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_report(str(forest),y_train,y_test,p_train_nb,p_test_forest)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:52.814462Z","iopub.execute_input":"2023-05-11T15:09:52.814772Z","iopub.status.idle":"2023-05-11T15:09:52.889577Z","shell.execute_reply.started":"2023-05-11T15:09:52.814745Z","shell.execute_reply":"2023-05-11T15:09:52.888418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boosting Classifier\nGradient boosting classifiers are a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model. Decision trees are usually used when doing gradient boosting. Boosting algorithms play a crucial role in dealing with bias variance trade-off.  Unlike bagging algorithms, which only controls for high variance in a model, boosting controls both the aspects (bias & variance), and is considered to be more effective. ","metadata":{}},{"cell_type":"code","source":"# Gradient Boosting Classifier Model\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# instantiate the model\ngbc = GradientBoostingClassifier(max_depth=4,learning_rate=0.7)\n\n# fit the model \ngbc.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:09:52.891089Z","iopub.execute_input":"2023-05-11T15:09:52.891469Z","iopub.status.idle":"2023-05-11T15:10:56.579377Z","shell.execute_reply.started":"2023-05-11T15:09:52.891438Z","shell.execute_reply":"2023-05-11T15:10:56.578299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\np_train_gbc = gbc.predict(X_train)\np_test_gbc = gbc.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:10:56.581029Z","iopub.execute_input":"2023-05-11T15:10:56.581403Z","iopub.status.idle":"2023-05-11T15:10:56.908178Z","shell.execute_reply.started":"2023-05-11T15:10:56.581365Z","shell.execute_reply":"2023-05-11T15:10:56.907031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_report(str(gbc),y_train,y_test,p_train_nb,p_test_gbc)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:10:56.909715Z","iopub.execute_input":"2023-05-11T15:10:56.910045Z","iopub.status.idle":"2023-05-11T15:10:56.986527Z","shell.execute_reply.started":"2023-05-11T15:10:56.910018Z","shell.execute_reply":"2023-05-11T15:10:56.984895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CatBoost Classifier\n\nCatBoost is a recently open-sourced machine learning algorithm from Yandex. It can easily integrate with deep learning frameworks like Google’s TensorFlow and Apple’s Core ML. It can work with diverse data types to help solve a wide range of problems that businesses face today.","metadata":{}},{"cell_type":"code","source":"#  catboost Classifier Model\nfrom catboost import CatBoostClassifier\n\n# instantiate the model\ncat = CatBoostClassifier(learning_rate  = 0.1)\n\n# fit the model \ncat.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:10:56.988088Z","iopub.execute_input":"2023-05-11T15:10:56.988513Z","iopub.status.idle":"2023-05-11T15:11:21.71531Z","shell.execute_reply.started":"2023-05-11T15:10:56.988481Z","shell.execute_reply":"2023-05-11T15:11:21.714344Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\np_train_cat = cat.predict(X_train)\np_test_cat = cat.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:11:21.716478Z","iopub.execute_input":"2023-05-11T15:11:21.716827Z","iopub.status.idle":"2023-05-11T15:11:21.816019Z","shell.execute_reply.started":"2023-05-11T15:11:21.716787Z","shell.execute_reply":"2023-05-11T15:11:21.814693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_report(str(cat),y_train,y_test,p_train_cat,p_test_cat)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:11:21.820031Z","iopub.execute_input":"2023-05-11T15:11:21.820861Z","iopub.status.idle":"2023-05-11T15:11:21.900914Z","shell.execute_reply.started":"2023-05-11T15:11:21.820824Z","shell.execute_reply":"2023-05-11T15:11:21.899705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  XGBoost Classifier\n\nXGBoost is an implementation of gradient boosted decision trees designed for speed and performance that is dominative competitive machine learning. In this post you will discover how you can install and create your first XGBoost model in Python","metadata":{}},{"cell_type":"code","source":"#  XGBoost Classifier Model\nfrom xgboost import XGBClassifier\n\n# instantiate the model\nxgb = XGBClassifier()\n\n# fit the model \nxgb.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:11:21.902259Z","iopub.execute_input":"2023-05-11T15:11:21.902654Z","iopub.status.idle":"2023-05-11T15:11:34.17943Z","shell.execute_reply.started":"2023-05-11T15:11:21.90262Z","shell.execute_reply":"2023-05-11T15:11:34.178485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\np_train_xgb = xgb.predict(X_train)\np_test_xgb = xgb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:11:34.181716Z","iopub.execute_input":"2023-05-11T15:11:34.182081Z","iopub.status.idle":"2023-05-11T15:11:34.37082Z","shell.execute_reply.started":"2023-05-11T15:11:34.182051Z","shell.execute_reply":"2023-05-11T15:11:34.369521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_report(str(xgb),y_train,y_test,p_train_xgb,p_test_xgb)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:11:34.373874Z","iopub.execute_input":"2023-05-11T15:11:34.374905Z","iopub.status.idle":"2023-05-11T15:11:34.48406Z","shell.execute_reply.started":"2023-05-11T15:11:34.374859Z","shell.execute_reply":"2023-05-11T15:11:34.481825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Multi-layer Perceptron classifier\n\nMLPClassifier stands for Multi-layer Perceptron classifier which in the name itself connects to a Neural Network. Unlike other classification algorithms such as Support Vectors or Naive Bayes Classifier, MLPClassifier relies on an underlying Neural Network to perform the task of classification.\n","metadata":{}},{"cell_type":"code","source":"# Multi-layer Perceptron Classifier Model\nfrom sklearn.neural_network import MLPClassifier\n\n# instantiate the model\nmlp = MLPClassifier()\n#mlp = GridSearchCV(mlpc, parameter_space)\n\n# fit the model \nmlp.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:11:34.485602Z","iopub.execute_input":"2023-05-11T15:11:34.486052Z","iopub.status.idle":"2023-05-11T15:12:05.303685Z","shell.execute_reply.started":"2023-05-11T15:11:34.486014Z","shell.execute_reply":"2023-05-11T15:12:05.302605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\np_train_mlp = mlp.predict(X_train)\np_test_mlp = mlp.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:12:05.305128Z","iopub.execute_input":"2023-05-11T15:12:05.305807Z","iopub.status.idle":"2023-05-11T15:12:05.372581Z","shell.execute_reply.started":"2023-05-11T15:12:05.305765Z","shell.execute_reply":"2023-05-11T15:12:05.370907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_report(str(mlp),y_train,y_test,p_train_mlp,p_test_mlp)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:12:05.374222Z","iopub.execute_input":"2023-05-11T15:12:05.37463Z","iopub.status.idle":"2023-05-11T15:12:05.50253Z","shell.execute_reply.started":"2023-05-11T15:12:05.374593Z","shell.execute_reply":"2023-05-11T15:12:05.501382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Comparision of Models\nTo compare the models performance, a dataframe is created. The columns of this dataframe are the lists created to store the results of the model.","metadata":{}},{"cell_type":"code","source":"#creating dataframe\nresult = pd.DataFrame({ 'ML Model' : ML_Model,\n                        'Accuracy' : accuracy,\n                        'f1_score' : f1_score,\n                        'Recall'   : recall,\n                        'Precision': precision,\n                      })","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:12:05.503949Z","iopub.execute_input":"2023-05-11T15:12:05.504408Z","iopub.status.idle":"2023-05-11T15:12:05.511755Z","shell.execute_reply.started":"2023-05-11T15:12:05.504362Z","shell.execute_reply":"2023-05-11T15:12:05.510553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sorting the datafram on accuracy\nsorted_result=result.sort_values(by=['Accuracy', 'f1_score'],ascending=False).reset_index(drop=True)\nsorted_result","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:12:05.513327Z","iopub.execute_input":"2023-05-11T15:12:05.514373Z","iopub.status.idle":"2023-05-11T15:12:05.538975Z","shell.execute_reply.started":"2023-05-11T15:12:05.514316Z","shell.execute_reply":"2023-05-11T15:12:05.537792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Storing High Score Model ","metadata":{}},{"cell_type":"code","source":"##  high_score_model ---> XGBoost Classifier Model\nimport pickle\n\nhigh_score_model = XGBClassifier()\n\nhigh_score_model.fit(X_train,y_train)\n\n# dump information to that file\n#pickle.dump(high_score_model, open('pickle/model.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:12:05.540679Z","iopub.execute_input":"2023-05-11T15:12:05.541137Z","iopub.status.idle":"2023-05-11T15:12:18.863222Z","shell.execute_reply.started":"2023-05-11T15:12:05.541097Z","shell.execute_reply":"2023-05-11T15:12:18.862231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pickle.dump(high_score_model, open('model.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:14:22.450623Z","iopub.execute_input":"2023-05-11T15:14:22.451066Z","iopub.status.idle":"2023-05-11T15:14:22.48338Z","shell.execute_reply.started":"2023-05-11T15:14:22.451031Z","shell.execute_reply":"2023-05-11T15:14:22.48228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the feature improtance in the model\nplt.figure(figsize=(9,7))\nn_features = X_train.shape[1]\nplt.barh(range(n_features), gbc.feature_importances_, align='center')\nplt.yticks(np.arange(n_features), X_train.columns)\nplt.title(\"Feature importances using permutation on full model\")\nplt.xlabel(\"Feature importance\")\nplt.ylabel(\"Feature\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T15:12:18.866364Z","iopub.execute_input":"2023-05-11T15:12:18.866748Z","iopub.status.idle":"2023-05-11T15:12:19.512813Z","shell.execute_reply.started":"2023-05-11T15:12:18.866715Z","shell.execute_reply":"2023-05-11T15:12:19.51149Z"},"trusted":true},"execution_count":null,"outputs":[]}]}